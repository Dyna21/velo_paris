import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
import folium
import warnings
warnings.filterwarnings('ignore')
#from streamlit_folium import folium_static


# Configuration de la page
st.set_page_config(
    page_title="V√©los √† Paris",
    page_icon="üö≤",
)

# Titre principal
st.title("üö≤ :blue[Trafic cycliste √† Paris]")

# Charger le fichier original pour le mettre en cache
@st.cache_data
def load_data(fichier):
    df = pd.read_csv(fichier,sep=';') # Download the data
    return df
df= load_data('comptage velo.csv')

# Charger le fichier corrig√©e pour le mettre en cache
@st.cache_data
def load_data1(fichier):
    df = pd.read_csv(fichier) # Download the data
    return df

df_corrected = load_data1('comptage velo corrected.csv')
# Convertir la colonne 'Date comptage' en datetime si elle n'est pas d√©j√† de ce type
df_corrected['Date comptage']= pd.to_datetime(df_corrected['Date comptage'])
df_corrected["Date installation"]= pd.to_datetime(df_corrected["Date installation"])


#df = pd.read_csv("comptage velo corrected.csv")

# Convertir la colonne 'Date comptage' en datetime si elle n'est pas d√©j√† de ce type
#df['Date comptage'] = pd.to_datetime(df['Date comptage'])
    
# Extraire la date sans l'heure
df_corrected['Date'] = df_corrected['Date comptage'].dt.date
    
# Agr√©ger les donn√©es par jour
daily_sum = df_corrected.groupby('Date').agg({'Comptage horaire': 'sum'}).reset_index()


# Barre lat√©rale avec les options de page
st.sidebar.title("Sommaire")
pages = ["Introduction", "Exploration des donn√©es üåç", "Visualisation üìä", "Mod√©lisation üíª", "Conclusion"]
page = st.sidebar.radio("Etapes", pages)

#Nom des contributeurs
st.sidebar.title("Contributeurs")
st.sidebar.markdown("[Cintyha Dina](https://www.linkedin.com/in/cintyha-dina-98396a97/)")
st.sidebar.markdown("[Pascal Paineau](https://www.linkedin.com/in/papaineau72/)")
st.sidebar.markdown("[Stephane Moisan](https://www.linkedin.com/in/stephanemoisan)")

# Logique pour afficher diff√©rentes pages
if page == "Introduction" :
    st.write("### :blue[Introduction]üëã")
    st.image("paris-velo.jpg")
    
    Texte="""Le projet que nous vous pr√©sentons aujourd'hui est une analyse des donn√©es collect√©es √† partir des compteurs √† v√©lo permanents que la Ville de Paris d√©ploie depuis plusieurs ann√©es d√©j√† afin d‚Äô√©valuer le d√©veloppement de la pratique cycliste."""
    st.markdown(f"<div style='text-align: justify'>{Texte}</div>", unsafe_allow_html=True)
    st.markdown(""" """)
    st.markdown(
        """
        
        **üëà Vous trouverez sur le volet √† gauche les diff√©rentes √©tapes de notre analyse.**
        
        ### :blue[Objectifs]
        
        """
    )
    Texte="""Notre principal objectif est de donner une vue d'ensemble de l'usage du v√©lo √† Paris et de faire √©merger des tendances afin d'aider √† la prise de d√©cision quant √† l'am√©nagement des pistes cyclables et les possibilit√©s d'investissement dans ce moyen de transport moins polluant que la voiture."""
    st.markdown(f"<div style='text-align: justify'>{Texte}</div>", unsafe_allow_html=True)


#-------------------------------------------------------------------------------------------------------------------
#EXPLORATION DES DONNEES
elif page == "Exploration des donn√©es üåç":
    st.write("### :blue[Exploration des donn√©es]üåç")

    # 1√®re partie ---------
    exploration_donnees = st.radio("**Diff√©rentes √©tapes d'analyse**", ("Fichier source", "Exploration","Pr√©paration", "Fichier de travail"), index=None)
    if exploration_donnees == "Fichier source":
        st.write("##### :blue[Pr√©sentation du jeu de donn√©es et mode de collecte]")
        
        Texte="""Dans le cadre du projet Data Analyst, nous avons utilis√© un jeu de donn√©es sur 12 mois glissants 
        (apr√®s retraitement) du 01/07/2022 au 30/06/2023 √† partir du fichier comptage-velo-donnees-compteurs.csv 
        extrait en date du 02/08/2023. """
        st.markdown(f"<div style='text-align: justify'>{Texte}</div>", unsafe_allow_html=True)
        st.markdown(""" """)
        st.markdown(
        """
        
    
        Ces donn√©es sont disponibles sur le site ¬´Paris data¬ª en open source sur le lien suivant :
         https://opendata.paris.fr/explore/dataset/comptage-velo-donneescompteurs/information/?disjunctive.id_compteur&disjunctive.nom_compteur&disjunctive.id&disjunctive.name 
     
    """
    )
        Texte="""Le jeu de donn√©es est charg√© quotidiennement sur l‚ÄôAPI du partenaire Eco Compteur √† Paris et √©volue chaque jour √† J-1.

Le fichier csv comporte un jeu de donn√©es des comptages horaires de v√©los par compteur et localisation des sites de comptage. 

Un site de comptage peut √™tre √©quip√© d‚Äôun compteur dans le cas d‚Äôun am√©nagement cyclable unidirectionnel ou de deux compteurs dans le cas d‚Äôun am√©nagement cyclable bidirectionnel. La Ville de Paris d√©ploie depuis plusieurs ann√©es des compteurs √† v√©lo permanents pour √©valuer le d√©veloppement de la pratique cycliste. 

Les compteurs sont situ√©s sur des pistes cyclables et dans certains couloirs de bus ouverts aux v√©los.

"""
        st.markdown(f"<div style='text-align: justify'>{Texte}</div>", unsafe_allow_html=True)


    if exploration_donnees == "Exploration":
        
        st.write("Affichage du jeu de donn√©es")
        st.dataframe(df.head())
    
       
        if st.checkbox("Afficher le data shape"):
                st.write(df.shape)
            
        elif st.checkbox("Afficher le descriptif"):
                st.write(df.describe())
    
        elif st.checkbox("Type"):
                st.write(df.dtypes)
    
        elif st.checkbox("Valeurs manquantes"):
                Val = df.isna.sum()/(len(df)*100)
                st.dataframe(Val)
    
        elif st.checkbox("Doublons"):
                Val=df.duplicated().sum()
                st.write("Nombre de doublons :", Val )
    
        elif st.checkbox("Caract√®res sp√©ciaux"):
                st.write("Les caract√©res sp√©ciaux √† chercher sont : .*[@_!#$%^&*()<>?/\|}{~:].*")
                st.write((df["Nom du compteur"][df["Nom du compteur"].str.contains(".*[@_!#$%^&*()<>?/\|}{~:].*",regex=True)].unique()))
    
    if exploration_donnees == "Pr√©paration":
        
        st.write("Affichage du jeu de donn√©es df_corrected")
        st.dataframe(df_corrected.head())
        
        if st.checkbox("Type df_corrected"):
                st.write(df_corrected.dtypes)
        
    if exploration_donnees == "Fichier de travail":
        
        st.write("Affichage du jeu de donn√©es df_corrected")
        st.dataframe(df_corrected.head())
        
        if st.checkbox("Afficher le data shape du jeu de donn√©es df_corrected"):
                st.write(df_corrected.shape)
                
            
        elif st.checkbox("Afficher le descriptif du jeu modifi√©"):
                st.dataframe(df_corrected.describe())


#-------------------------------------------------------------------------------------------------------------------
#VISUALISATION
elif page == "Visualisation üìä":
    st.write("### :blue[Visualisation des donn√©es]üìä")
    st.markdown("### Pr√©sentation du trafic cycliste √† Paris")
    
    selectbox = st.selectbox ("**El√©ments d'analyse visuelle :**", ("Choisir un graphique", "Evolution de l'installation des compteurs par ann√©e", "Evolution du nombre de kilom√®tres am√©nag√©s","R√©partition des compteurs dans la ville", "Affichage des compteurs selon le nombre de passage"))
    if selectbox == "Evolution de l'installation des compteurs par ann√©e" :
        # Convertir les colonnes de dates en type datetime
        df_corrected['Date comptage'] = pd.to_datetime(df_corrected['Date comptage'])
        df_corrected['Date installation'] = pd.to_datetime(df_corrected['Date installation'])

        # Extraire l'ann√©e d'installation des compteurs
        df_corrected['Annee installation'] = df_corrected['Date installation'].dt.year

        # Compter le nombre de compteurs install√©s par ann√©e
        counts_by_year = df_corrected['Annee installation'].value_counts().sort_index()

        # Visualiser le nombre de compteurs install√©s par ann√©e
        st.write("Nombre de compteurs install√©s chaque ann√©e :")
        st.bar_chart(counts_by_year)


    if selectbox == "Evolution du nombre de kilom√®tres am√©nag√©s":
        Ev_res = {
            "Ann√©e": [2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022],
            "Lin√©aire en km": [292.8, 327.3, 370.9, 399.3, 439.5, 446.2, 647.5, 654.8, 677, 732.5, 737.5, 742.1, 779.8, 835.6, 912.6, 1037.05, 1136.3, 1170.8, 1202.5]
        }
        df_piste = pd.DataFrame(Ev_res)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        df_piste.plot(kind="bar", x="Ann√©e", y="Lin√©aire en km", width=0.7, color="blue", ax=ax)
        
        ax.set_title("Evolution du nombre de kilom√®tres am√©nag√©s", fontsize=14, fontweight='bold')
        ax.set_xlabel('Ann√©e')
        ax.set_ylabel('Nombre de kilom√®tres am√©nag√©s')
        ax.tick_params(axis='x', rotation=45)
        
        st.pyplot(fig) 

    
   

    if selectbox == "R√©partition des compteurs dans la ville":
        df_plan = df_corrected.drop_duplicates(subset="Nom du compteur", keep='first')

        # Cr√©er la carte avec Folium
        paris = folium.Map(location=[48.856578, 2.351828],zoom_start=12, min_zoom=12, max_zoom=18)

        # Ajouter une couche
        folium.TileLayer('openstreetmap').add_to(paris)

        # Ajouter un marqueur pour chaque compteur
        for index, row in df_plan.iterrows():
            folium.Marker(location=[row["Latitude"], row["Longitude"]],
                        popup=row["Nom du compteur"],
                        tooltip="Cliquez ici pour voir le nom du compteur").add_to(paris)

        # Ajouter un contr√¥le de couches √† la carte
        folium.LayerControl().add_to(paris)

        # Afficher la carte Folium dans Streamlit
        folium_static(paris)


    

    if selectbox == "Affichage des compteurs selon le nombre de passage":
        # Cr√©er la carte avec Folium
        paris = folium.Map(location=[48.856578, 2.351828], zoom_start=12, min_zoom=12, max_zoom=18)

        # Grouper les donn√©es par compteur et calculer la somme des passages
        df_plan_sum = df_corrected.groupby(['Nom du compteur', "Latitude", "Longitude"])['Comptage horaire'].sum().reset_index()

        # D√©finir la couleur en fonction du nombre de passages
        def colorer_zone(comptage):
            if comptage > seuil:
                return 'red'  # zones avec plus de passages en rouge
            else:
                return 'green'  # zones avec moins de passages en vert

        # D√©finir le seuil pour diff√©rencier les zones avec plus ou moins de passages
        seuil = df_plan_sum['Comptage horaire'].quantile(0.75)  # par exemple, seuil √† 75√®me percentile

        # Ajouter des marqueurs de cercle pour chaque zone avec couleur bas√©e sur le nombre de passages
        for index, row in df_plan_sum.iterrows():
            folium.CircleMarker(location=[row["Latitude"], row["Longitude"]],
                                popup=row["Comptage horaire"],
                                radius=row["Comptage horaire"] / 100000,
                                fill=True,
                                color=colorer_zone(row["Comptage horaire"]),
                                tooltip="Cliquez ici pour voir le nombre de passage").add_to(paris)

        # Afficher la carte Folium dans Streamlit
        folium_static(paris)



#Visualisation du trafic en fonction de la temporalit√©
    temporalite = st.radio('**Nombre de passage des v√©los sur quelle p√©riode ?**', ('Jour', 'Semaine', 'Mois', 'Ann√©e'), index=None)
    if temporalite == 'Jour':
        df_graph = df_corrected.copy()
        df_graph['Heure comptage']=(df_graph['Date comptage'].dt.time)
        df_graph = df_graph[['Heure comptage', 'Comptage horaire']]
        df_compt_hour = df_graph.groupby("Heure comptage").mean()
        fig, ax = plt.subplots(figsize=(10, 6))
        df_compt_hour.plot(kind='bar', color='green', ax=ax)
        plt.title("Sur une journ√©e", fontsize=14, fontweight='bold')
        plt.xlabel('Heure de comptage')
        plt.ylabel('Moyenne des passages')
        plt.xticks(rotation=45)
        plt.tight_layout()  
        st.pyplot(fig)

    if temporalite == "Mois" :
        df_graph = df_corrected.copy()
        df_graph = df_graph[(df_graph['Date comptage']>='2023-04-01') & (df_graph['Date comptage']<'2023-05-01')]
        hebdo_sum = df_graph.groupby(df_graph['Date comptage'].dt.to_period("d")).agg({'Comptage horaire': 'sum'}).reset_index()
        fig = plt.figure(figsize=(10, 6))
        x=hebdo_sum['Date comptage'].dt.start_time
        y=hebdo_sum['Comptage horaire']
        plt.plot(x, y,linestyle='-', marker='o')
        plt.title("Sur le mois d'avril 2023",fontsize=14,fontweight='bold')
        plt.xlabel('Jour')
        plt.ylabel('Nombre de comptage')
        plt.xticks(rotation=45)
        plt.annotate(
            'Week-end',fontweight='bold',color='green', xy=(110, 140), xytext=(120, 100),xycoords='figure points',
                    arrowprops=dict(facecolor='green', shrink=0.05))
        plt.annotate(
            '',fontweight='bold',color='green', xy=(250, 100), xytext=(180, 105),xycoords='figure points',
                    arrowprops=dict(facecolor='green', shrink=0.05))
        plt.annotate(
            'Gr√®ves',fontweight='bold',color='red', xy=(290, 260), xytext=(280, 110),xycoords='figure points',
                    arrowprops=dict(facecolor='red', shrink=0.05))
        plt.annotate(
            '',fontweight='bold',color='red', xy=(335, 180), xytext=(320, 125),xycoords='figure points',
                    arrowprops=dict(facecolor='red', shrink=0.05))
        plt.annotate(
            '',fontweight='bold',color='red', xy=(480, 90), xytext=(320, 110),xycoords='figure points',
                    arrowprops=dict(facecolor='red', shrink=0.05))
        plt.annotate(
            'Week-end',fontweight='bold',color='green', xy=(340, 190), xytext=(390, 170),xycoords='figure points',
                    arrowprops=dict(facecolor='green', shrink=0.05))
        plt.annotate(
            'Week-end',fontweight='bold',color='green', xy=(480, 100), xytext=(520, 100),xycoords='figure points',
                    arrowprops=dict(facecolor='green', shrink=0.05))
        st.pyplot(fig)


    if temporalite == "Ann√©e":
        
        df_graph = df_corrected.copy()
        df_graph['Jour'] = df_graph['Date comptage'].dt.strftime('%Y-%m-%d')
        df_graph['Mois'] = df_graph['Date comptage'].dt.strftime('%Y-%m')
        monthly_sum = df_graph.groupby('Mois')['Comptage horaire'].sum().reset_index()

        # Cr√©er un graphique √† barres
        fig, ax = plt.subplots(figsize=(10, 6))
        x = monthly_sum['Mois']
        y = monthly_sum['Comptage horaire']
        ax.bar(x, y, width=0.9, alpha=0.5, color=['blue', 'blue', 'blue', 'green', 'green', 'green', 'yellow', 'yellow', 'yellow', 'orange', 'orange', 'orange'])
        
        def addlabels(x,y):
            for i in range(len(x)):
                plt.text(i, y[i], y[i], ha='center',
                bbox=dict(facecolor='red', alpha=.2), fontsize=8, fontweight='bold')

        addlabels(x, y)
        plt.title('Sur une ann√©e', fontweight='bold')
        plt.xlabel('Mois')
        plt.ylabel('Nombre de comptage')
        plt.xticks(rotation=45)

        # Ajouter des annotations avec des fl√®ches
        ax.annotate('Vacances de No√´l', fontweight='bold', color='royalblue', xy=(290, 220), xytext=(300, 300), xycoords='figure points',
                    arrowprops=dict(facecolor='fuchsia', shrink=0.05))
        ax.annotate('Vacances d\'√©t√©', fontweight='bold', color='royalblue', xy=(120, 250), xytext=(70, 350), xycoords='figure points',
                    arrowprops=dict(facecolor='fuchsia', shrink=0.05))
        ax.annotate('Jours f√©ri√©s et ponts', fontweight='bold', color='royalblue', xy=(460, 310), xytext=(380, 350), xycoords='figure points',
                    arrowprops=dict(facecolor='fuchsia', shrink=0.05))

        st.pyplot(fig)

    if temporalite == "Semaine":
        df_graph = df_corrected.copy()
        
        # Filtrer les donn√©es pour ne consid√©rer que la premi√®re semaine de juin
        first_week_june = df_graph[(df_graph['Date comptage'].dt.month == 6) & (df_graph['Date comptage'].dt.day >= 1) & (df_graph['Date comptage'].dt.day <= 7)]
        
        # Grouper par jour et calculer le nombre total de passages de v√©los pour chaque jour
        passages_per_day = first_week_june.groupby(df_graph['Date comptage'].dt.dayofweek).agg({'Comptage horaire': 'sum'}).reset_index()
        
        # Convertir le num√©ro du jour en nom complet du jour de la semaine en fran√ßais
        jours_semaine_fr = {0: 'Lundi', 1: 'Mardi', 2: 'Mercredi', 3: 'Jeudi', 4: 'Vendredi', 5: 'Samedi', 6: 'Dimanche'}
        passages_per_day['Jour de la semaine'] = passages_per_day['Date comptage'].apply(lambda x: jours_semaine_fr[x])
        
        # Plot
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.bar(passages_per_day['Jour de la semaine'], passages_per_day['Comptage horaire'], color='blue')
        ax.set_title('Sur la premi√®re semaine de juin', fontsize=14, fontweight='bold')
        ax.set_xlabel('Jours de la semaine')
        ax.set_ylabel('Nombre de passages de v√©los')
        ax.tick_params(axis='x', rotation=45)  # Rotation des dates pour une meilleure lisibilit√©
        
        st.pyplot(fig)


#-------------------------------------------------------------------------------------------------------------------
#MODELISATION
elif page == "Mod√©lisation üíª":
    st.write("### :blue[Mod√©lisation]üíª")
    
    st.markdown("### :black[Choix du mod√®le]")
    st.markdown("""Notre choix s'est port√© sur un mod√©le de :blue[S√©ries temporelles] du fait que nous avons observ√© une forte d√©pendance temporelle dans ce dataframe.""")
    st.divider()
    
    presentation_modelisation = st.radio('**Nombre de passage des v√©los sur quelle p√©riode ?**', ("D√©composition", "Choix param√®tres","Mod√©lisation"), index=None)

    if presentation_modelisation == "D√©composition" :
        st.markdown("##### :black[D√©composition]")
        df_corrected['Date comptage']= pd.to_datetime(df_corrected['Date comptage'])
        velo_decomp = df_corrected.copy()
        velo_decomp['Jour'] = velo_decomp['Date comptage'].dt.strftime('%Y-%m-%d')
        velo_decomp = velo_decomp.groupby('Jour')['Comptage horaire'].sum().reset_index()
        velo_decomp = velo_decomp.sort_values(by = 'Jour')
        velo_decomp['Jour']= pd.to_datetime(velo_decomp['Jour'])
        velo_decomp.set_index('Jour', inplace=True)
        
        option = st.selectbox(
       "Choix de la d√©composition ?",
       ("D√©composition Additif", "D√©composition Multiplicatif"),
       index=None,
       placeholder="Selection de la d√©composition...",
    )

        
        if option =="D√©composition Additif":
            
            st.markdown("##### :blue[D√©composition additif]")
            st.divider()
            
            #D√©composition additif
            from statsmodels.tsa.seasonal import seasonal_decompose
            decomposition = seasonal_decompose(velo_decomp)
            trend = decomposition.trend
            seasonal = decomposition.seasonal
            residual = decomposition.resid
            
            fig = plt.figure(figsize=(20, 6))
            plt.plot(trend)
            plt.title('Tendance',fontsize=26,fontweight='bold')
            st.pyplot(fig)
            
            fig = plt.figure(figsize=(20, 6))
            plt.plot(seasonal)
            plt.title('Saisonnalit√©',fontsize=26,fontweight='bold')
            st.pyplot(fig)
            
            fig = plt.figure(figsize=(20, 6))
            plt.plot(residual,"o")
            plt.title('R√©sidus',fontsize=26,fontweight='bold')
            st.pyplot(fig)
            
            fig = plt.figure(figsize=(20, 6))
            pd.plotting.autocorrelation_plot(velo_decomp)
            plt.title('Autocorrelation',fontsize=26,fontweight='bold')
            st.pyplot(plt.gcf())
            

            from statsmodels.graphics.tsaplots import plot_acf,plot_pacf
            fig,(ax1,ax2) = plt.subplots(2,1,figsize=(20,6))
            plot_acf(velo_decomp['Comptage horaire'], lags=30, zero=True, ax=ax1)
            ax1.set_title('ACF - S√©rie de comptage horaire',fontsize=26,fontweight='bold')
            ax1.set_xlabel('Lag')
            ax1.set_ylabel('Corr√©lation')
            ax1.grid(True)
            
            plot_pacf(velo_decomp['Comptage horaire'], lags=30, zero=True, ax=ax2)
            ax2.set_title('PACF - S√©rie de comptage horaire',fontsize=26,fontweight='bold')
            ax2.set_xlabel('Lag')
            ax2.set_ylabel('Corr√©lation partielle')
            ax2.grid(True)
            plt.tight_layout()
            st.pyplot(fig)
            
            from statsmodels.tsa.stattools import adfuller
            result=adfuller(velo_decomp)
            st.write ("Valeur de test : ",(result[0]))  
            st.write ("P-valeur : " ,(result[1])) 
            st.markdown ("Conclusion : :red[La s√©rie n'est pas stationnaire]")
            
        elif option =="D√©composition Multiplicatif":
            
            st.markdown("##### :blue[D√©composition Multiplicatif]")
            st.divider()
            
            #D√©composition multiplicative
            from statsmodels.tsa.seasonal import seasonal_decompose
            decomposition = seasonal_decompose(velo_decomp, model = 'multiplicative')
            trend = decomposition.trend
            seasonal = decomposition.seasonal
            residual = decomposition.resid
            
            fig = plt.figure(figsize=(20, 6))
            plt.plot(trend)
            plt.title('Tendance',fontsize=26,fontweight='bold')
            st.pyplot(fig)
            
            fig = plt.figure(figsize=(20, 6))
            plt.plot(seasonal)
            plt.title('Saisonnalit√©',fontsize=26,fontweight='bold')
            st.pyplot(fig)
            
            fig = plt.figure(figsize=(20, 6))
            plt.plot(residual,"o")
            plt.title('R√©sidus',fontsize=26,fontweight='bold')
            st.pyplot(fig)


            st.markdown("##### :blue[Retour √† un mod√©le additif]")
            st.divider()
            velo_decomp_log = np.log(velo_decomp)
            st.line_chart(velo_decomp_log)
            plt.xticks(rotation=45)
            
            st.markdown("##### :blue[Choix diff√©renciation]")
            st.divider()
            col1, col2 = st.columns(2)
            col1.write("**Diff√©renciation simple**")
            col2.write("**Diff√©renciation d'ordre 7**")
            
            fig = plt.subplots(1, 2, figsize=(10,6))
            plt.title("Diff√©renciation simple",fontsize=18,fontweight='bold')
            velo_decomp_log_1 = velo_decomp_log.diff().dropna()
            col1.line_chart(velo_decomp_log_1)
            
            fig = plt.subplots(1, 2, figsize=(10,6))
            plt.title("Diff√©renciation d'ordre 7",fontsize=18,fontweight='bold')
            velo_decomp_log_2 = velo_decomp_log_1.diff(periods = 7).dropna()
            col2.line_chart(velo_decomp_log_2)
            
            fig = plt.subplots(figsize=(10,6))
            pd.plotting.autocorrelation_plot(velo_decomp_log_1)
            plt.title("Autocorrelation simple",fontsize=18,fontweight='bold')
            col1.pyplot(plt.gcf())
            
            fig = plt.subplots(figsize=(10,6))
            pd.plotting.autocorrelation_plot(velo_decomp_log_2)
            plt.title("Autocorrelation d'ordre 7",fontsize=18,fontweight='bold')
            col2.pyplot(plt.gcf())
            
            from statsmodels.tsa.stattools import adfuller
            result=adfuller(velo_decomp_log_2)
            st.write ('Valeur de test : ', result[0])
            st.write ('P-valeur : ', result[1])
            st.markdown ("Conclusion : :green[La s√©rie est stationnaire]")
                                   
    if presentation_modelisation == "Choix param√®tres":
                        
        df_corrected['Date comptage']= pd.to_datetime(df_corrected['Date comptage'])
        velo_decomp = df_corrected.copy()
        velo_decomp['Jour'] = velo_decomp['Date comptage'].dt.strftime('%Y-%m-%d')
        velo_decomp = velo_decomp.groupby('Jour')['Comptage horaire'].sum().reset_index()
        velo_decomp = velo_decomp.sort_values(by = 'Jour')
        velo_decomp['Jour']= pd.to_datetime(velo_decomp['Jour'])
        velo_decomp.set_index('Jour', inplace=True)
        velo_decomp_log = np.log(velo_decomp)
        velo_decomp_log_1 = velo_decomp_log.diff().dropna()
        velo_decomp_log_2 = velo_decomp_log_1.diff(periods = 7).dropna()
        
        st.markdown("##### :blue[Etude ACF et PACF avec diff√©renciation d'ordre 7]")
        from statsmodels.graphics.tsaplots import plot_acf,plot_pacf
        fig,(ax1,ax2) = plt.subplots(2,1,figsize=(20,6))
        plot_acf(velo_decomp_log_2['Comptage horaire'], lags=30, zero=True, ax=ax1)
        ax1.set_title('ACF - S√©rie de comptage horaire',fontsize=26,fontweight='bold')
        ax1.set_xlabel('Lag')
        ax1.set_ylabel('Corr√©lation')
        ax1.grid(True)
        
        plot_pacf(velo_decomp_log_2['Comptage horaire'], lags=30, zero=True, ax=ax2)
        ax2.set_title('PACF - S√©rie de comptage horaire',fontsize=26,fontweight='bold')
        ax2.set_xlabel('Lag')
        ax2.set_ylabel('Corr√©lation partielle')
        ax2.grid(True)
        plt.tight_layout()
        st.pyplot(fig)
        
        st.markdown("##### :blue[Choix param√®tres]")
        Texte = """  Pour la partie non saisonni√®re, on en a estim√© que le un processus  ARMA(ùëù,ùëû) serait ARMA(1,1)."""
        st.markdown(""":green[ORDER] :""")
        st.markdown(f"<div style='text-align: justify'>{Texte}</div>", unsafe_allow_html=True)  

        Texte="""Pour les ordres saisonniers (ùëÉ et ùëÑ), il suffit de se r√©f√©rer aux m√™mes r√®gles mais en regardant uniquement les pics saisonniers (les 7√®me, 14√®me, 21√®me, 28√®me pics). Ainsi on peut estimer pour la partie saisonni√®re un processus MA(1) ce qui est √©quivalent √† un  ARMA(0,1)"""
        st.markdown(""" """)
        st.markdown(""":green[SEASONAL ORDER] :""")
        st.markdown(f"<div style='text-align: justify'>{Texte}</div>", unsafe_allow_html=True)
        
        Texte = """* Une d√©croissance de l'ACF et la PACF sans coupure nette : mod√®le  ARMA(1,1), (Il est possible de rajouter des termes si le mod√®le ne semble pas suffisamment performant)
* Pour les pics saisonniers, une coupure de l'ACF apr√®s la premi√®re p√©riode et une d√©croissance de la PACF : mod√®le  MA(1).
* Et une d√©composition d'ordre 7."""
        st.markdown(""" """)
        st.markdown(""":green[POUR CONCLURE] :""")
        #st.markdown(f"<div style='text-align: justify'>{Texte}</div>", unsafe_allow_html=True)
        st.markdown(Texte)
        st.markdown("""Nous entrainerons donc un mod√®le :blue[SARIMA(1,1,1)(0,1,1)7]""")

        velo_decomp = df_corrected.copy()
        velo_decomp['Jour'] = velo_decomp['Date comptage'].dt.strftime('%Y-%m-%d')
        velo_decomp = velo_decomp.groupby('Jour')['Comptage horaire'].sum().reset_index()
        velo_decomp = velo_decomp.sort_values(by = 'Jour')
        velo_decomp['Jour']= pd.to_datetime(velo_decomp['Jour'])
        velo_decomp.set_index('Jour', inplace=True)

        #S√©parer mon jeu de donn√©es en jeu d'entrainement et jeu de test
        train_data = velo_decomp[:round(len(velo_decomp)*70/100)]
        test_data = velo_decomp[round(len(velo_decomp)*70/100):]

        Tableau = st.checkbox('Affichage SARIMAX')

        if Tableau:

            #Sarima2
            model=sm.tsa.SARIMAX(train_data,order=(1,1,1),seasonal_order=(0,1,1,7))
            sarima2=model.fit()
            st.write(sarima2.summary())
        
    if presentation_modelisation == "Mod√©lisation":

        velo_decomp = df_corrected.copy()
        velo_decomp['Jour'] = velo_decomp['Date comptage'].dt.strftime('%Y-%m-%d')
        velo_decomp = velo_decomp.groupby('Jour')['Comptage horaire'].sum().reset_index()
        velo_decomp = velo_decomp.sort_values(by = 'Jour')
        velo_decomp['Jour']= pd.to_datetime(velo_decomp['Jour'])
        velo_decomp.set_index('Jour', inplace=True)

        #S√©parer mon jeu de donn√©es en jeu d'entrainement et jeu de test
        train_data = velo_decomp[:round(len(velo_decomp)*70/100)]
        test_data = velo_decomp[round(len(velo_decomp)*70/100):]

        st.markdown("##### :blue[Mod√©lisation]")
        st.markdown("Nous avons aussi proc√©der √† une recherche automatique pour trouver les meilleurs param√®tres √† prendre en compte. Il nous a √©t√© propos√© le mod√®le :blue[SARIMA(1,0,1)(0,1,1)7]")
        st.divider()
        
        #Sarima2
        model=sm.tsa.SARIMAX(train_data,order=(1,0,1),seasonal_order=(0,1,1,7))
        sarima2=model.fit()
        
        train_predictions = sarima2.predict(start = train_data.index[0], end = train_data.index[-1])
        test_predictions = sarima2.predict(start = test_data.index[0], end = test_data.index[-1])
        
        col1, col2 = st.columns(2)
        col1.write("**Mod√®le propos√© avec order=(1,0,1)**")
        col2.write("**Mod√®le d√©duit avec order=(1,1,1)**")
    
        #Calculer les diff√©rents m√©triques
        from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score
        #Mesure la d√©viation absolue moyenne entre une estimation pr√©vue et les donn√©es r√©elles. - np.mean(abs(diff)))
        train_mae = mean_absolute_error(train_data,train_predictions)
        #La distance, entre la pr√©vision et l‚Äôobservation, est ici √©lev√©e au carr√©. La sensibilit√© √† l‚Äôerreur est meilleure - np.mean(diff**2)
        train_mse = mean_squared_error(train_data,train_predictions)
        #C'est la racine carr√©e du MSE, c‚Äôest une m√©trique largement utilis√©e - np.sqrt(mse)
        train_rsme = mean_squared_error(train_data,train_predictions, squared=False)
        #1-(sum(diff**2)/sum((y_true-np.mean(y_true))**2))
        train_r2 = r2_score(train_data, train_predictions)
        
        test_mae = mean_absolute_error(test_data,test_predictions)
        test_mse = mean_squared_error(test_data,test_predictions)
        test_rsme = mean_squared_error(test_data,test_predictions, squared=False)
        test_r2 = r2_score(test_data, test_predictions)
        
        performance_df = pd.DataFrame({
            'M√©trique' : ['MAE', 'MSE','RMSE', 'R2'],
            'Ensemble (Entrainement)' : (train_mae, train_mse, train_rsme, train_r2),
            'Ensemble (Test)' : (test_mae, test_mse, test_rsme, test_r2)})
        col1.dataframe(performance_df)
    
    #Visualisation du mod√©le sur les jeux d'entrainements et de tests
        from datetime import date

        
        fig=plt.figure(figsize=(10,6))
        plt.plot(train_data.index, train_data.values, label='Ensemble (Entrainement)', color='red')
        plt.plot(test_data.index, test_data.values, label='Ensemble (Test)', color='green')
        plt.plot(train_predictions.index, train_predictions.values, label='Pr√©dictions (Entrainement)', color='blue', linestyle='--')
        plt.plot(test_predictions.index, test_predictions.values, label='Pr√©dictions (Test)', color='blue', linestyle='--')
        
        plt.xlim(train_data.index[0], test_data.index[-1])

        plt.xlabel('Date')
        plt.ylabel('comptage')
        plt.title("Choix du mod√©le SARIMA",fontweight='bold')
        plt.xticks(rotation=45)
        plt.axvline(x= date(2023,3,15), color='black', linestyle='--')
        plt.legend()
        plt.annotate('Entrainement',fontweight='bold',color='black', xy=(480, 100), xytext=(380, 100),xycoords='figure points')
        plt.annotate('Test',fontweight='bold',color='black', xy=(480, 100), xytext=(520, 100),xycoords='figure points')
        plt.show();
        col1.pyplot(fig)
    
        #Sarima1
        model1=sm.tsa.SARIMAX(train_data,order=(1,1,1),seasonal_order=(0,1,1,7))
        sarima1=model1.fit()
        
        train_predictions = sarima1.predict(start = train_data.index[0], end = train_data.index[-1])
        test_predictions = sarima1.predict(start = test_data.index[0], end = test_data.index[-1])
    
        #Calculer les diff√©rents m√©triques
        #Mesure la d√©viation absolue moyenne entre une estimation pr√©vue et les donn√©es r√©elles. - np.mean(abs(diff)))
        train_mae = mean_absolute_error(train_data,train_predictions)
        #La distance, entre la pr√©vision et l‚Äôobservation, est ici √©lev√©e au carr√©. La sensibilit√© √† l‚Äôerreur est meilleure - np.mean(diff**2)
        train_mse = mean_squared_error(train_data,train_predictions)
        #C'est la racine carr√©e du MSE, c‚Äôest une m√©trique largement utilis√©e - np.sqrt(mse)
        train_rsme = mean_squared_error(train_data,train_predictions, squared=False)
        #1-(sum(diff**2)/sum((y_true-np.mean(y_true))**2))
        train_r2 = r2_score(train_data, train_predictions)
        
        test_mae = mean_absolute_error(test_data,test_predictions)
        test_mse = mean_squared_error(test_data,test_predictions)
        test_rsme = mean_squared_error(test_data,test_predictions, squared=False)
        test_r2 = r2_score(test_data, test_predictions)
        
        performance_df = pd.DataFrame({
            'M√©trique' : ['MAE', 'MSE','RMSE', 'R2'],
            'Ensemble (Entrainement)' : (train_mae, train_mse, train_rsme, train_r2),
            'Ensemble (Test)' : (test_mae, test_mse, test_rsme, test_r2)})
        col2.dataframe(performance_df)
    
        #Visualisation du mod√©le sur les jeux d'entrainements et de tests
        from datetime import date
        fig=plt.figure(figsize=(10,6))
        plt.plot(train_data.index, train_data.values, label='Ensemble (Entrainement)', color='red')
        plt.plot(test_data.index, test_data.values, label='Ensemble (Test)', color='green')
        plt.plot(train_predictions.index, train_predictions.values, label='Pr√©dictions (Entrainement)', color='blue', linestyle='--')
        plt.plot(test_predictions.index, test_predictions.values, label='Pr√©dictions (Test)', color='blue', linestyle='--')
        
        plt.xlim(train_data.index[0], test_data.index[-1])
    
        plt.xlabel('Date')
        plt.ylabel('comptage')
        plt.title("Choix du mod√©le SARIMA",fontweight='bold')
        plt.xticks(rotation=45)
        plt.axvline(x= date(2023,3,15), color='black', linestyle='--')
        plt.legend()
        plt.annotate('Entrainement',fontweight='bold',color='black', xy=(480, 100), xytext=(380, 100),xycoords='figure points')
        plt.annotate('Test',fontweight='bold',color='black', xy=(480, 100), xytext=(520, 100),xycoords='figure points')
        plt.show();
        col2.pyplot(fig)
    
        Prediction = st.checkbox('Pr√©diction')

        futureDate = pd.DataFrame(pd.date_range(start='2023-07-01', end='2023-09-30',freq='D'),columns=['Dates'])
        futureDate.set_index('Dates',inplace=True)
        
        #Graphique pr√©diction
        train_predictions = sarima1.predict(start = train_data.index[0], end = train_data.index[-1])
        test_predictions = sarima1.predict(start = test_data.index[0], end = test_data.index[-1])
        
        fig=plt.figure(figsize=(10,6))
        plt.plot(train_data.index, train_data.values, label='Entrainement', color='red')
        plt.plot(test_data.index, test_data.values, label='Test', color='green')
        sarima1.predict(start=futureDate.index[0], end=futureDate.index[-1]).plot(label='Pr√©diction',color='blue');
        
        plt.xlim(train_data.index[0], futureDate.index[-1])
        #plt.ylim(min(train_data.min(), test_data.min()), max(train_data.max(),test_data.max()))
        
        plt.xlabel('Date')
        plt.ylabel('comptage')
        plt.title("Pr√©diction avec le mod√©le SARIMA",fontweight='bold')
        plt.xticks(rotation=45)
        plt.axvline(x= date(2023,3,15), color='black', linestyle='--')
        plt.axvline(x= date(2023,6,30), color='black', linestyle='--')
        plt.legend()
        plt.annotate('Entrainement',fontweight='bold',color='black', xy=(480, 100), xytext=(300, 100),xycoords='figure points')
        plt.annotate('Test',fontweight='bold',color='black', xy=(480, 100), xytext=(430, 100),xycoords='figure points')
        plt.annotate('Pr√©diction',fontweight='bold',color='black', xy=(480, 100), xytext=(540, 100),xycoords='figure points')
      
        if Prediction:
            
            st.pyplot(fig)
            
elif page == "Conclusion":
    st.write("### :blue[Conclusion]üòÄ")
    # Ajoutez ici votre conclusion ou vos r√©sultats finaux

